{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b2541a",
   "metadata": {},
   "source": [
    "## LSTM models\n",
    "We developed 4 models with two extra modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c3730",
   "metadata": {},
   "source": [
    "## Model Summaries\n",
    "TThis project explores a sequence of LSTM architectures to predict next-day stock direction using engineered price-based features. The progression begins with simple sequence modeling and gradually incorporates deeper nonlinear layers, longer temporal context, and finally multi-stock learning through symbol embeddings.\n",
    "\n",
    "The modeling narrative evolves as follows:\n",
    "\n",
    "Model 1 establishes a minimal baseline LSTM for binary movement prediction.\n",
    "\n",
    "Models 2 explore deeper dense layers, dropout, and extended training to assess whether nonlinear transformations or longer convergence improve performance.\n",
    "\n",
    "Models 3-A and 3-B transition to multi-stock learning, adding a symbol-embedding pathway that allows the LSTM to learn stock-specific patterns jointly across all tickers.\n",
    "\n",
    "Finally, the project investigates how architectural complexity, embedding size, and dense depth affect generalization.\n",
    "\n",
    "Across all models, results consistently show that historical OHLCV data alone provides insufficient predictive signal for next-day price direction. Performance remains close to random, suggesting that future modeling efforts should incorporate richer feature sets (technical indicators, sentiment, macro factors) and longer windows.\n",
    "\n",
    "\n",
    "Here is the summary of the models architecture, key aspect and their performance\n",
    "\n",
    "| **Model**                                | **Architecture / Setup**                                                                                           | **Key Idea**                                                                                  |\n",
    "|------------------------------------------|---------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|\n",
    "| **Model 1 – Baseline LSTM**             | LSTM(64) → Dropout(0.2) → Dense(1, sigmoid); 20-day window                                                         | Minimal LSTM baseline to test whether past OHLCV data can support next-day direction labels. |\n",
    "| **Model 2 – Deeper LSTM**             | LSTM(64) → Dense(64, softplus) → Dropout(0.1) → Dense(12, softplus) → Dense(1, sigmoid); 20-day window             | Adds nonlinear dense layers and a tuned Adam optimizer to enrich feature representation.      |\n",
    "| **Model 3-A – Multi-Stock LSTM + Emb**  | Embedding(8) → Flatten → RepeatVector → Concatenate with sequence → LSTM(64) → Dropout(0.2) → Dense(32, softplus) → Dense(1, sigmoid); 60-day window | Introduces ticker embeddings so the LSTM can learn shared patterns across multiple symbols.   |\n",
    "| **Model 3-B – Deeper Multi-Stock LSTM** | Embedding(12) → Flatten → RepeatVector → Concatenate with sequence → LSTM(64) → Dense(64, softplus) → Dropout(0.2) → Dense(32, softplus) → Dropout(0.2) → Dense(1, sigmoid); 60-day window | Uses a larger embedding and deeper dense head to increase capacity for cross-stock structure. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acb43e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheki\\dsi\\project\\Stock-Trend-Analysis-with-NYSE\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9119a68",
   "metadata": {},
   "source": [
    "## Data preparation, introducing the features, and loading engineered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d52d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 20\n",
      "Features: ['open', 'high', 'low', 'close', 'volume', 'log_return_1d', 'close_lag1', 'log_return_lag1', 'log_return_lag2', 'log_return_lag3', 'rolling_mean_5', 'rolling_mean_10', 'rolling_std_5', 'rolling_std_10', 'momentum_5', 'momentum_10', 'volume_change_1d', 'volume_zscore_10', 'high_low_ratio', 'close_open_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Defining features list\n",
    "base_features = [    'open',    'high',    'low',    'close',    'volume',    'log_return_1d']\n",
    "extra_features = [\n",
    "'close_lag1', 'log_return_lag1', 'log_return_lag2', 'log_return_lag3', 'rolling_mean_5', 'rolling_mean_10', 'rolling_std_5', 'rolling_std_10',\n",
    " 'momentum_5', 'momentum_10', 'volume_change_1d', 'volume_zscore_10', 'high_low_ratio', 'close_open_ratio']\n",
    "\n",
    "features = base_features + extra_features\n",
    "target_cls = 'price_up_tomorrow'\n",
    "print(\"Num features:\", len(features))\n",
    "print(\"Features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99acfb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['symbol',\n",
       " 'date',\n",
       " 'price_up_tomorrow',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'log_return_1d',\n",
       " 'close_lag1',\n",
       " 'log_return_lag1',\n",
       " 'log_return_lag2',\n",
       " 'log_return_lag3',\n",
       " 'rolling_mean_5',\n",
       " 'rolling_mean_10',\n",
       " 'rolling_std_5',\n",
       " 'rolling_std_10',\n",
       " 'momentum_5',\n",
       " 'momentum_10',\n",
       " 'volume_change_1d',\n",
       " 'volume_zscore_10',\n",
       " 'high_low_ratio',\n",
       " 'close_open_ratio']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cols = ['symbol', 'date', target_cls] + features\n",
    "# Loading the optimized data file \n",
    "\n",
    "df_fe = pd.read_parquet(\"../data/processed/price_features.parquet\",\n",
    "                        columns=use_cols)\n",
    "list(df_fe.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8fec3",
   "metadata": {},
   "source": [
    "## Bulding sequences for each symbol\n",
    "The goal is to build time-series sequences per stock (as beeing used later on for LSTM input)\n",
    "We define a windoe (here 20-days) as look-back window, fixing the random seed, using the six scaled price/volume features, and setting the binary target price_up_tomorrow. \n",
    "\n",
    "The helper funciton \"make_sequences_symbol()\" sorts each symbol’s data by date and creates sliding windows of shape (window=20, features=6). For each window it pairs the next day’s target label, returning:\n",
    "    X: NumPy array of sequences with shape (n_samples, 20, 6)\n",
    "    y: NumPy array of binary labels (n_samples, )\n",
    "\n",
    "These sequences are later concatenated across symbols and used to train LSTM models while preserving time order (with no leakage)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd2126",
   "metadata": {},
   "source": [
    "Making a general sequence builder for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ba955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence builder (needed for all the models)\n",
    "def make_sequences_symbol(sequence, features, target, window):\n",
    "    \"\"\"\n",
    "    Building sliding-window sequences for a single symbol.\n",
    "\n",
    "    sequence : DataFrame for one symbol\n",
    "    features : list of feature column names (inputs)\n",
    "    target   : name of target column\n",
    "    window   : look-back length (e.g. 20, 60, 100)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray, shape (n_samples, window, n_features), dtype float32\n",
    "    y : np.ndarray, shape (n_samples,), dtype float32\n",
    "    \"\"\"\n",
    "    # Ensure correct temporal order; no .copy() to avoid extra memory\n",
    "    sequence = sequence.sort_values('date')\n",
    "\n",
    "    # Drop any rows where inputs or target are NaN\n",
    "    sequence = sequence.dropna(subset=features + [target])\n",
    "\n",
    "    # Convert to numeric arrays, explicitly float32 to save RAM\n",
    "    vals = sequence[features].to_numpy(dtype='float32')  # (N, F)\n",
    "    tgt  = sequence[target].to_numpy(dtype='float32')    # (N,)\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    # Build sliding windows\n",
    "    for i in range(window, len(sequence)):\n",
    "        X.append(vals[i-window:i])  # shape (window, n_features)\n",
    "        y.append(tgt[i])            # scalar target for day after the window\n",
    "\n",
    "    return np.array(X, dtype='float32'), np.array(y, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4566e",
   "metadata": {},
   "source": [
    "## General Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc92ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets while keeping the data's time order\n",
    "def build_X_y(df, features, target, window, train_frac=0.8):\n",
    "    \"\"\"\n",
    "    Build train/test sequences across all symbols.\n",
    "\n",
    "    df         : full dataframe (already sorted by symbol/date at top)\n",
    "    features   : list of feature column names\n",
    "    target     : target column name\n",
    "    window     : look-back length (e.g. 20, 60, 100)\n",
    "    train_frac : fraction of each symbol's history used for training\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : (N_train, window, n_features) float32\n",
    "    y_train : (N_train,) float32\n",
    "    X_test  : (N_test,  window, n_features) float32\n",
    "    y_test  : (N_test,) float32\n",
    "    \"\"\"\n",
    "    X_tr, y_tr = [], []\n",
    "    X_te, y_te = [], []\n",
    "\n",
    "    # Loop over each stock and build sequences separately\n",
    "    for sym, g in df.groupby('symbol'):\n",
    "        # df is already globally sorted, but we keep this for safety (no copy here)\n",
    "        g = g.sort_values('date')\n",
    "\n",
    "        n = len(g)\n",
    "        if n < window + 1:\n",
    "            continue  # not enough history for this symbol\n",
    "\n",
    "        cut = int(n * train_frac)\n",
    "        g_tr = g.iloc[:cut]\n",
    "        g_te = g.iloc[cut:]\n",
    "\n",
    "        X1, y1 = make_sequences_symbol(g_tr, features, target, window)\n",
    "        X2, y2 = make_sequences_symbol(g_te, features, target, window)\n",
    "\n",
    "        if len(X1):\n",
    "            X_tr.append(X1); y_tr.append(y1)\n",
    "        if len(X2):\n",
    "            X_te.append(X2); y_te.append(y2)\n",
    "\n",
    "    if not X_tr or not X_te:\n",
    "        raise ValueError(\"No sequences were built. Check window size and data coverage per symbol.\")\n",
    "\n",
    "    X_train = np.concatenate(X_tr, axis=0).astype('float32')\n",
    "    y_train = np.concatenate(y_tr, axis=0).astype('float32')\n",
    "    X_test  = np.concatenate(X_te, axis=0).astype('float32')\n",
    "    y_test  = np.concatenate(y_te, axis=0).astype('float32')\n",
    "\n",
    "    print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d21a5fa",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "### Description: \n",
    "A simple one-layer LSTM with 64 units, 20-day window, and dropout (0.2) trained on six scaled price features to predict price_up_tomorrow.\n",
    "\n",
    "First baseline model; establishes core sequence-to-label pipeline using minimal architecture and binary cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c13e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (666189, 20, 20) X_test: (159520, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# defining the parameters\n",
    "window_m1 = 20\n",
    "target_cls = 'price_up_tomorrow'   # same as before\n",
    "\n",
    "X_train_m1, y_train_m1, X_test_m1, y_test_m1 = build_X_y(\n",
    "    df_fe, features, target_cls, window=window_m1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf3b6f",
   "metadata": {},
   "source": [
    "Since we were getting errors, need to cleanup the data for another extra step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db827a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 666034 of 666189 samples\n",
      "Keeping 159480 of 159520 samples\n",
      "X_train_m1: (666034, 20, 20) X_test_m1: (159480, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "def clean_Xy(X, y):\n",
    "    # rows where ALL features across the window are finite\n",
    "    mask_X = np.isfinite(X.reshape(X.shape[0], -1)).all(axis=1)\n",
    "    mask_y = np.isfinite(y)\n",
    "    mask = mask_X & mask_y\n",
    "    \n",
    "    print(\"Keeping\", mask.sum(), \"of\", len(mask), \"samples\")\n",
    "    return X[mask].astype('float32'), y[mask].astype('float32')\n",
    "\n",
    "X_train_m1, y_train_m1 = clean_Xy(X_train_m1, y_train_m1)\n",
    "X_test_m1,  y_test_m1  = clean_Xy(X_test_m1,  y_test_m1)\n",
    "\n",
    "print(\"X_train_m1:\", X_train_m1.shape, \"X_test_m1:\", X_test_m1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4024d5a",
   "metadata": {},
   "source": [
    "Building model 1 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f784b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                21760     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,825\n",
      "Trainable params: 21,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 1 architecture\n",
    "model1 = Sequential([\n",
    "    LSTM(\n",
    "        64,\n",
    "        input_shape=(X_train_m1.shape[1], X_train_m1.shape[2]),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),  # changing to small L2 to stabilize\n",
    "        recurrent_dropout=0.1                               # regularize recurrent part\n",
    "    ),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "opt1 = Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "\n",
    "model1.compile(\n",
    "    optimizer=opt1,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4064340",
   "metadata": {},
   "source": [
    "Model 1 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929247d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2342/2342 [==============================] - 100s 42ms/step - loss: 0.6970 - accuracy: 0.5074 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 2/20\n",
      "2342/2342 [==============================] - 102s 44ms/step - loss: 0.6930 - accuracy: 0.5135 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 3/20\n",
      "2342/2342 [==============================] - 100s 43ms/step - loss: 0.6929 - accuracy: 0.5142 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 4/20\n",
      "2342/2342 [==============================] - 98s 42ms/step - loss: 0.6928 - accuracy: 0.5151 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 5/20\n",
      "2342/2342 [==============================] - 99s 42ms/step - loss: 0.6930 - accuracy: 0.5133 - val_loss: 0.6927 - val_accuracy: 0.5161\n"
     ]
    }
   ],
   "source": [
    "# Train the model 1\n",
    "es = EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "history1 = model1.fit(\n",
    "    X_train_m1, y_train_m1,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,\n",
    "    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c7c84",
   "metadata": {},
   "source": [
    "## Model 1 - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2710008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4984/4984 [==============================] - 14s 3ms/step\n",
      "Model 1 – Accuracy: 0.520573112616002\n",
      "Confusion matrix:\n",
      " [[    2 76459]\n",
      " [    0 83019]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      1.000     0.000     0.000     76461\n",
      "         1.0      0.521     1.000     0.685     83019\n",
      "\n",
      "    accuracy                          0.521    159480\n",
      "   macro avg      0.760     0.500     0.342    159480\n",
      "weighted avg      0.750     0.521     0.356    159480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob_m1 = model1.predict(X_test_m1).ravel()\n",
    "y_pred_m1 = (y_prob_m1 >= 0.5).astype(int)\n",
    "# evaluation using accuracy, confusion_matrix and generating report\n",
    "print(\"Model 1 – Accuracy:\", accuracy_score(y_test_m1, y_pred_m1))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_m1, y_pred_m1))\n",
    "print(\"Classification report:\\n\", classification_report(y_test_m1, y_pred_m1, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90145f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred prob range: 0.4864463 0.5161737\n",
      "Pred prob range: 0.4864463 0.5161737\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred prob range:\", y_prob_m1.min(), y_prob_m1.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3bc3d",
   "metadata": {},
   "source": [
    "## Model 1 - Interpretation:\n",
    "\n",
    "Feature redundancy:\n",
    "We are using correlated inputs (open, high, low, close), and later on we added (in this final code) engineered features which contain overlapping price information dervide from the same inputs (open, high, low, close). Because the model’s predicted probabilities cluster tightly around 0.50 (0.486–0.516), this redundancy does not contribute meaningful independent signal, and limits new pattern extraction that could improve discrimination.\n",
    "\n",
    "Inherent prediction difficulty:\n",
    "Daily stock direction is dominated by external, non-price factors (macroeconomic news, market sentiment, unexpected events). With only historical prices and volume, the signal-to-noise ratio is very low — hence the near-random (~0.50) accuracy. The model ultimately predicts almost exclusively the majority class (“up”), confirming that the available features provide too little signal to separate up vs. down days.\n",
    "\n",
    "Temporal limitation:\n",
    "The 20-day look-back window may be too short to capture meaningful market momentum or medium-term trends. The narrow probability range further indicates that the model cannot form sufficiently strong temporal patterns from this limited window. Extending the sequence length (e.g., 50–100 days) or adding derived trend features could improve temporal learning.\n",
    "\n",
    "Later models (Models 2 and 3) address this by exploring:\n",
    "\n",
    "-   deeper neural architectures,\n",
    "\n",
    "-   longer look-back windows (e.g., 60–100 days), and\n",
    "\n",
    "-   symbol embeddings for multi-stock learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605123cf",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------\n",
    "## Model 2 – Deeper LSTM with dense layers (on engineered features)\n",
    "Description: \n",
    "Added two fully connected Dense layers (64 → 12 → 1) using softplus activations and lighter dropout (0.1) for richer nonlinear mapping.\n",
    "\n",
    "New vs Model 1: \n",
    "Introduces hidden dense layers and tuned optimizer (Adam with β₁ = 0.95) to improve representational power and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc08572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 64)                21760     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 12)                780       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,713\n",
      "Trainable params: 26,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model2 = Sequential([\n",
    "    LSTM(64, input_shape=(X_train_m1.shape[1], X_train_m1.shape[2])),\n",
    "    Dense(64, activation='softplus'),\n",
    "    Dropout(0.1),\n",
    "    Dense(12, activation='softplus'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "opt2 = Adam(learning_rate=1e-2, beta_1=0.95, beta_2=0.999)\n",
    "\n",
    "model2.compile(optimizer=opt2,\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26f155",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af2aa3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2342/2342 [==============================] - 62s 26ms/step - loss: 0.6928 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 2/20\n",
      "2342/2342 [==============================] - 58s 25ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 3/20\n",
      "2342/2342 [==============================] - 58s 25ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 4/20\n",
      "2342/2342 [==============================] - 58s 25ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 5/20\n",
      "2342/2342 [==============================] - 65s 28ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 6/20\n",
      "2342/2342 [==============================] - 64s 27ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 7/20\n",
      "2342/2342 [==============================] - 65s 28ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 8/20\n",
      "2342/2342 [==============================] - 60s 26ms/step - loss: 0.6927 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "4984/4984 [==============================] - 18s 3ms/step\n",
      "Model 2 – Accuracy: 0.5205605718585402\n",
      "Confusion matrix:\n",
      " [[    0 76461]\n",
      " [    0 83019]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000     76461\n",
      "         1.0      0.521     1.000     0.685     83019\n",
      "\n",
      "    accuracy                          0.521    159480\n",
      "   macro avg      0.260     0.500     0.342    159480\n",
      "weighted avg      0.271     0.521     0.356    159480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the model 2\n",
    "es2 = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "history2 = model2.fit(\n",
    "    X_train_m1, y_train_m1,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,\n",
    "    callbacks=[es2]\n",
    ")\n",
    "# evaluation\n",
    "y_prob_2 = model2.predict(X_test_m1).ravel()\n",
    "y_pred_2 = (y_prob_2 >= 0.5).astype(int)\n",
    "\n",
    "print(\"Model 2 – Accuracy:\", accuracy_score(y_test_m1, y_pred_2))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_m1, y_pred_2))\n",
    "print(\"Classification report:\\n\", classification_report(y_test_m1, y_pred_2, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393224e9",
   "metadata": {},
   "source": [
    "## Model 2  - Interpretation:\n",
    "\n",
    "Model 2 fail to learn any useful patterns: \n",
    "\n",
    "the loss remains flat at ~0.692 throughout training, and the model collapses to predicting only one class (here, always the positive class “1”), despite the additional dense layers and modified optimizer. \n",
    "\n",
    "This behavior now occurs even after removing NaNs and infinities, indicating that the instability is not due to data quality but rather the absence of predictive signal in the features. \n",
    "\n",
    "The deeper architecture in model 2 compared to model 1, did not extract more information from the inputs, and optimization remains unable to move away from random-chance performance. \n",
    "Which highlights that adding network depth alone does not improve predictive power when the underlying features contain very limited signal, and richer inputs—not increased architectural complexity—are required to extract meaningful patterns from price-only data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a687116",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "## Model 3 – Multi-Stock LSTM with Symbol Embeddings (Models 3-A and 3-B)\n",
    "\n",
    "In this section we develop two related models—Model 3-A and Model 3-B—both based on a multi-stock architecture that incorporates symbol embeddings.\n",
    "\n",
    "Description:\n",
    "\n",
    "These models extend the earlier single-stock LSTMs by adding a symbol embedding layer that learns a dense vector representation for each ticker.\n",
    "Instead of training a separate model for each stock, all stocks are trained jointly. Each sequence now has two inputs:\n",
    "\n",
    "A 60-day feature sequence (OHLCV + engineered features)\n",
    "\n",
    "A symbol ID that identifies the stock\n",
    "\n",
    "The symbol ID is passed through an embedding layer and the resulting vector is repeated across the full time window and concatenated to the feature sequence at every timestep.\n",
    "This allows the model to learn both:\n",
    "\n",
    "    -temporal patterns in the stock’s historical prices\n",
    "    -stock-specific behavior encoded in the learned embedding\n",
    "    -What is new compared to earlier models\n",
    "    -Moves from single-stock modeling to a joint multi-stock architecture\n",
    "    -Introduces a learned embedding vector for each ticker\n",
    "    -Uses a dual-input LSTM (sequence + symbol ID)\n",
    "    -Enables the model to capture cross-stock similarities and differences\n",
    "\n",
    "Model Variants:\n",
    "\n",
    "    Model 3-A: a simpler embedding-enhanced LSTM with a small embedding dimension (8) and a light dense head.\n",
    "         Designed to establish the effectiveness of multi-stock learning.\n",
    "\n",
    "    Model 3-B: a deeper version with:\n",
    "        larger embedding dimension (12)\n",
    "        additional dense layers\n",
    "        increased dropout\n",
    "        higher learning rate\n",
    "        This variant tests whether a richer representation improves generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96db64",
   "metadata": {},
   "source": [
    "Data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a835bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of symbols: 501\n",
      "Example symbol mapping (first 5): [('A', 0), ('AAL', 1), ('AAP', 2), ('AAPL', 3), ('ABBV', 4)]\n",
      "Model 3 – X_train: (646149, 60, 20) X_test: (139535, 60, 20) sym_train: (646149,) sym_test: (139535,)\n",
      "sym_train shape: (646149, 1)\n",
      "sym_test shape: (139535, 1)\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation for Model 3 – Multi-stock LSTM with symbol embeddings (data preparation)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1) Target + window for this model\n",
    "target_cls = 'price_up_tomorrow'   # same target as Models 1 & 2\n",
    "window_m3  = 60                    # 60-day look-back window\n",
    "\n",
    "# 2) Mapping: symbol -> integer ID (for embeddings)\n",
    "symbols = sorted(df_fe['symbol'].unique())\n",
    "sym2id  = {s: i for i, s in enumerate(symbols)}\n",
    "\n",
    "print(f\"Number of symbols: {len(symbols)}\")\n",
    "print(\"Example symbol mapping (first 5):\", list(sym2id.items())[:5])\n",
    "\n",
    "\n",
    "def build_X_y_with_symbols(df, features, target, window, train_frac=0.8):\n",
    "    \"\"\"\n",
    "    Build train/test sequences across all symbols, plus symbol IDs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train_m3 : (N_train, window, n_features) float32\n",
    "    y_train_m3 : (N_train,) float32\n",
    "    sym_train  : (N_train,) int32   symbol IDs for each sequence\n",
    "    X_test_m3  : (N_test,  window, n_features) float32\n",
    "    y_test_m3  : (N_test,) float32\n",
    "    sym_test   : (N_test,) int32\n",
    "    \"\"\"\n",
    "    X_tr, y_tr, S_tr = [], [], []\n",
    "    X_te, y_te, S_te = [], [], []\n",
    "\n",
    "    for sym, g in df.groupby('symbol'):\n",
    "        g = g.sort_values('date')          # df_fe is already sorted, but this is cheap\n",
    "        n = len(g)\n",
    "        if n < window + 1:\n",
    "            continue\n",
    "\n",
    "        sym_id = sym2id[sym]\n",
    "        cut = int(n * train_frac)\n",
    "        g_tr = g.iloc[:cut]\n",
    "        g_te = g.iloc[cut:]\n",
    "\n",
    "        # reuse our generic sequence builder\n",
    "        X1, y1 = make_sequences_symbol(g_tr, features, target, window)\n",
    "        X2, y2 = make_sequences_symbol(g_te, features, target, window)\n",
    "\n",
    "        if len(X1):\n",
    "            X_tr.append(X1)\n",
    "            y_tr.append(y1)\n",
    "            S_tr.append(np.full(len(y1), sym_id, dtype='int32'))\n",
    "\n",
    "        if len(X2):\n",
    "            X_te.append(X2)\n",
    "            y_te.append(y2)\n",
    "            S_te.append(np.full(len(y2), sym_id, dtype='int32'))\n",
    "\n",
    "    if not X_tr or not X_te:\n",
    "        raise ValueError(\"No sequences built for Model 3 – check window_m3 and data length per symbol.\")\n",
    "\n",
    "    X_train_m3 = np.concatenate(X_tr, axis=0).astype('float32')\n",
    "    y_train_m3 = np.concatenate(y_tr, axis=0).astype('float32')\n",
    "    sym_train  = np.concatenate(S_tr, axis=0)\n",
    "\n",
    "    X_test_m3  = np.concatenate(X_te, axis=0).astype('float32')\n",
    "    y_test_m3  = np.concatenate(y_te, axis=0).astype('float32')\n",
    "    sym_test   = np.concatenate(S_te, axis=0)\n",
    "\n",
    "    print(\"Model 3 – X_train:\", X_train_m3.shape,\n",
    "          \"X_test:\", X_test_m3.shape,\n",
    "          \"sym_train:\", sym_train.shape,\n",
    "          \"sym_test:\", sym_test.shape)\n",
    "\n",
    "    return X_train_m3, y_train_m3, sym_train, X_test_m3, y_test_m3, sym_test\n",
    "\n",
    "\n",
    "# 3) building the datasets for Model 3\n",
    "X_train_m3, y_train_m3, sym_train, X_test_m3, y_test_m3, sym_test = build_X_y_with_symbols(\n",
    "    df_fe, features, target_cls, window=window_m3 )\n",
    "\n",
    "# To make sure that symbol ID arrays have shape (N, 1) for the Keras Input(shape=(1,))\n",
    "sym_train = sym_train.reshape(-1, 1)\n",
    "sym_test  = sym_test.reshape(-1, 1)\n",
    "\n",
    "print(\"sym_train shape:\", sym_train.shape)\n",
    "print(\"sym_test shape:\", sym_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457cc392",
   "metadata": {},
   "source": [
    "Data cleanup form Nans (as without this block we get errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdfea80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed (train): 218 samples\n",
      "Removed (test) : 120 samples\n",
      "After cleaning:\n",
      "X_train_m3: (645931, 60, 20) NaNs: 0\n",
      "y_train_m3: (645931,) NaNs: 0\n",
      "X_test_m3 : (139415, 60, 20) NaNs: 0\n",
      "y_test_m3 : (139415,) NaNs: 0\n",
      "sym_train : (645931, 1)\n",
      "sym_test  : (139415, 1)\n"
     ]
    }
   ],
   "source": [
    "#  CLEAN NaNs / infinities \n",
    "\n",
    "def _row_finite_mask(X):\n",
    "    return np.isfinite(X.reshape(X.shape[0], -1)).all(axis=1)\n",
    "\n",
    "mask_train = (\n",
    "    _row_finite_mask(X_train_m3) &\n",
    "    np.isfinite(y_train_m3) &\n",
    "    np.isfinite(sym_train.reshape(-1))\n",
    ")\n",
    "\n",
    "mask_test = (\n",
    "    _row_finite_mask(X_test_m3) &\n",
    "    np.isfinite(y_test_m3) &\n",
    "    np.isfinite(sym_test.reshape(-1))\n",
    ")\n",
    "\n",
    "print(\"Removed (train):\", (~mask_train).sum(), \"samples\")\n",
    "print(\"Removed (test) :\", (~mask_test).sum(), \"samples\")\n",
    "\n",
    "X_train_m3 = X_train_m3[mask_train]\n",
    "y_train_m3 = y_train_m3[mask_train]\n",
    "sym_train  = sym_train[mask_train]\n",
    "\n",
    "X_test_m3  = X_test_m3[mask_test]\n",
    "y_test_m3  = y_test_m3[mask_test]\n",
    "sym_test   = sym_test[mask_test]\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"X_train_m3:\", X_train_m3.shape, \"NaNs:\", np.isnan(X_train_m3).sum())\n",
    "print(\"y_train_m3:\", y_train_m3.shape, \"NaNs:\", np.isnan(y_train_m3).sum())\n",
    "print(\"X_test_m3 :\", X_test_m3.shape, \"NaNs:\", np.isnan(X_test_m3).sum())\n",
    "print(\"y_test_m3 :\", y_test_m3.shape, \"NaNs:\", np.isnan(y_test_m3).sum())\n",
    "print(\"sym_train :\", sym_train.shape)\n",
    "print(\"sym_test  :\", sym_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c705fea",
   "metadata": {},
   "source": [
    "## Model 3A - Multi-stock LSTM with symbol embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b74b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sym_in (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " sym_emb (Embedding)            (None, 1, 8)         4008        ['sym_in[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 8)            0           ['sym_emb[0][0]']                \n",
      "                                                                                                  \n",
      " seq_in (InputLayer)            [(None, 60, 20)]     0           []                               \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 60, 8)        0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 60, 28)       0           ['seq_in[0][0]',                 \n",
      "                                                                  'repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 64)           23808       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 32)           2080        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            33          ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,929\n",
      "Trainable params: 29,929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 3A - Multi-stock LSTM with symbol embeddings\n",
    "from tensorflow.keras.layers import Input, Embedding, RepeatVector, Concatenate, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Infer sequence length (T) and number of features (F) from the training data\n",
    "T, F = X_train_m3.shape[1], X_train_m3.shape[2]\n",
    "vocab_size = len(symbols)   # number of distinct tickers\n",
    "emb_dim    = 8              # embedding dimension , smaller better to prevent overfitting\n",
    "\n",
    "#  Inputs \n",
    "seq_in = Input(shape=(T, F), name='seq_in')           \n",
    "sym_in = Input(shape=(1,), dtype='int32', name='sym_in')  # symbol ID\n",
    "\n",
    "#  Symbol embedding pathway \n",
    "sym_emb = Embedding(input_dim=vocab_size,\n",
    "                    output_dim=emb_dim,\n",
    "                    name='sym_emb')(sym_in)   \n",
    "\n",
    "sym_vec = Flatten()(sym_emb)     \n",
    "sym_rep = RepeatVector(T)(sym_vec)\n",
    "\n",
    "#  Combine symbol embedding with sequence features \n",
    "x = Concatenate(axis=-1)([seq_in, sym_rep])   \n",
    "\n",
    "#  LSTM + Dense classifier \n",
    "x = LSTM(64)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='softplus')(x)       \n",
    "out = Dense(1, activation='sigmoid')(x)       # probability of \"price_up_tomorrow\"\n",
    "\n",
    "#  Build and compile model \n",
    "model3 = Model(inputs=[seq_in, sym_in], outputs=out)\n",
    "\n",
    "opt3 = Adam(learning_rate=3e-4, beta_1=0.95, beta_2=0.999)\n",
    "\n",
    "model3.compile(optimizer=opt3,\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cf51cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2271/2271 [==============================] - 187s 81ms/step - loss: 0.6934 - accuracy: 0.5101 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 2/20\n",
      "2271/2271 [==============================] - 185s 82ms/step - loss: 0.6930 - accuracy: 0.5118 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 3/20\n",
      "2271/2271 [==============================] - 189s 83ms/step - loss: 0.6930 - accuracy: 0.5125 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 4/20\n",
      "2271/2271 [==============================] - 188s 83ms/step - loss: 0.6930 - accuracy: 0.5122 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 5/20\n",
      "2271/2271 [==============================] - 177s 78ms/step - loss: 0.6929 - accuracy: 0.5125 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 6/20\n",
      "2271/2271 [==============================] - 184s 81ms/step - loss: 0.6929 - accuracy: 0.5126 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 7/20\n",
      "2271/2271 [==============================] - 185s 81ms/step - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 8/20\n",
      "2271/2271 [==============================] - 185s 82ms/step - loss: 0.6929 - accuracy: 0.5126 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 9/20\n",
      "2271/2271 [==============================] - 186s 82ms/step - loss: 0.6929 - accuracy: 0.5133 - val_loss: 0.6927 - val_accuracy: 0.5146\n",
      "Epoch 10/20\n",
      "2271/2271 [==============================] - 186s 82ms/step - loss: 0.6929 - accuracy: 0.5125 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 11/20\n",
      "2271/2271 [==============================] - 187s 83ms/step - loss: 0.6929 - accuracy: 0.5132 - val_loss: 0.6927 - val_accuracy: 0.5146\n",
      "Epoch 12/20\n",
      "2271/2271 [==============================] - 188s 83ms/step - loss: 0.6929 - accuracy: 0.5129 - val_loss: 0.6927 - val_accuracy: 0.5146\n",
      "Epoch 13/20\n",
      "2271/2271 [==============================] - 188s 83ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 14/20\n",
      "2271/2271 [==============================] - 189s 83ms/step - loss: 0.6929 - accuracy: 0.5133 - val_loss: 0.6927 - val_accuracy: 0.5146\n"
     ]
    }
   ],
   "source": [
    "# Train the model3-A\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es3 = EarlyStopping(\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    monitor='val_loss' )\n",
    "\n",
    "history3 = model3.fit(\n",
    "    [X_train_m3, sym_train],   # two inputs: sequences + symbol IDs\n",
    "    y_train_m3,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,\n",
    "    callbacks=[es3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbfc81a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357/4357 [==============================] - 34s 8ms/step\n",
      "Model 3 – Accuracy: 0.5165297851737618\n",
      "Model 3 – ROC-AUC: 0.4999851638651099\n",
      "Confusion matrix:\n",
      " [[    0 67403]\n",
      " [    0 72012]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000     67403\n",
      "         1.0      0.517     1.000     0.681     72012\n",
      "\n",
      "    accuracy                          0.517    139415\n",
      "   macro avg      0.258     0.500     0.341    139415\n",
      "weighted avg      0.267     0.517     0.352    139415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Model 3-A evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Predicted probabilities\n",
    "y_prob_3 = model3.predict([X_test_m3, sym_test]).ravel()\n",
    "y_pred_3 = (y_prob_3 >= 0.5).astype(int)\n",
    "\n",
    "print(\"Model 3 – Accuracy:\", accuracy_score(y_test_m3, y_pred_3))\n",
    "print(\"Model 3 – ROC-AUC:\", roc_auc_score(y_test_m3, y_prob_3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_m3, y_pred_3))\n",
    "print(\"Classification report:\\n\", classification_report(y_test_m3, y_pred_3, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c38b5",
   "metadata": {},
   "source": [
    "## Model 3-B - tuned hyperparameters: New learning rate and number of epochs, etc..\n",
    "\n",
    "Description: Increases embedding dimension (12), adds extra dense + dropout layers, and raises learning rate (3e-3) and epochs (60) for better fitting capacity.\n",
    "\n",
    "New vs previous Model 4: Expands network depth and regularization, refines learning rate/epochs for performance tuning.\n",
    "\n",
    "Compared to Model 3-A, this version:\n",
    "\n",
    "    -expands the symbol embedding size (e.g., from 8 → 12),\n",
    "\n",
    "    -deepens the post-LSTM network (additional Dense + Dropout layers),\n",
    "\n",
    "    -increases training epochs and learning rate for stronger optimization.\n",
    "\n",
    "These changes are intended to enhance the model’s ability to learn richer latent patterns shared across tickers while still retaining the dual-input embedding architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ed5475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sym_in (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " sym_emb (Embedding)            (None, 1, 12)        6012        ['sym_in[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 12)           0           ['sym_emb[0][0]']                \n",
      "                                                                                                  \n",
      " seq_in (InputLayer)            [(None, 60, 20)]     0           []                               \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVector)  (None, 60, 12)      0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 60, 32)       0           ['seq_in[0][0]',                 \n",
      "                                                                  'repeat_vector_1[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 64)           24832       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           4160        ['lstm_6[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           2080        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 32)           0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            33          ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 37,117\n",
      "Trainable params: 37,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 3-B – deeper multi-stock LSTM with embeddings\n",
    "from tensorflow.keras.layers import Input, Embedding, RepeatVector, Concatenate, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Using the shapes from the Model 3-A data\n",
    "T, F = X_train_m3.shape[1], X_train_m3.shape[2]\n",
    "vocab_size = len(symbols)\n",
    "emb_dim    = 12   # larger embedding than Model 3-A\n",
    "\n",
    "# Inputs\n",
    "seq_in = Input(shape=(T, F), name='seq_in')\n",
    "sym_in = Input(shape=(1,), dtype='int32', name='sym_in')\n",
    "\n",
    "# Symbol embedding pathway\n",
    "sym_emb = Embedding(input_dim=vocab_size,\n",
    "                    output_dim=emb_dim,\n",
    "                    name='sym_emb')(sym_in)\n",
    "sym_vec = Flatten()(sym_emb)\n",
    "sym_rep = RepeatVector(T)(sym_vec)  \n",
    "\n",
    "# Concatenate sequence features with repeated symbol embedding\n",
    "x = Concatenate(axis=-1)([seq_in, sym_rep]) \n",
    "\n",
    "# LSTM + deeper dense \n",
    "x = LSTM(64)(x)\n",
    "x = Dense(64, activation='softplus')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='softplus')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Output layer: binary classification\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Build and compile model\n",
    "model3b = Model(inputs=[seq_in, sym_in], outputs=out)\n",
    "opt3b   = Adam(learning_rate=3e-3, beta_1=0.95, beta_2=0.999)\n",
    "\n",
    "model3b.compile(optimizer=opt3b,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model3b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b93db3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357/4357 [==============================] - 34s 8ms/step\n",
      "Raw shapes:\n",
      "  y_test_m3: (139415,)\n",
      "  y_prob_3b: (139415,)\n",
      "NaNs in y_test_m3: 0\n",
      "NaNs in y_prob_3b: 0\n",
      "Total test samples: 139415\n",
      "Valid samples after NaN-filtering: 139415\n",
      "Model 3-B – Accuracy: 0.5165297851737618\n",
      "Model 3-B – ROC-AUC: 0.4998105499207182\n",
      "Confusion matrix:\n",
      " [[    0 67403]\n",
      " [    0 72012]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000     67403\n",
      "         1.0      0.517     1.000     0.681     72012\n",
      "\n",
      "    accuracy                          0.517    139415\n",
      "   macro avg      0.258     0.500     0.341    139415\n",
      "weighted avg      0.267     0.517     0.352    139415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation – Model 3-B (robust to NaNs)\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# 1) Raw probabilities from the model\n",
    "y_prob_3b = model3b.predict([X_test_m3, sym_test]).ravel()\n",
    "\n",
    "print(\"Raw shapes:\")\n",
    "print(\"  y_test_m3:\", y_test_m3.shape)\n",
    "print(\"  y_prob_3b:\", y_prob_3b.shape)\n",
    "print(\"NaNs in y_test_m3:\", np.isnan(y_test_m3).sum())\n",
    "print(\"NaNs in y_prob_3b:\", np.isnan(y_prob_3b).sum())\n",
    "\n",
    "# 2) Mask out any samples where either y_true or y_prob is NaN\n",
    "nan_mask = ~np.isnan(y_test_m3) & ~np.isnan(y_prob_3b)\n",
    "\n",
    "print(\"Total test samples:\", len(y_test_m3))\n",
    "print(\"Valid samples after NaN-filtering:\", nan_mask.sum())\n",
    "\n",
    "# If *everything* is NaN, avoid crashing ROC-AUC\n",
    "if nan_mask.sum() == 0:\n",
    "    print(\"No valid (non-NaN) samples for evaluation.\")\n",
    "else:\n",
    "    y_true_clean = y_test_m3[nan_mask]\n",
    "    y_prob_clean = y_prob_3b[nan_mask]\n",
    "    y_pred_clean = (y_prob_clean >= 0.5).astype(int)\n",
    "\n",
    "    print(\"Model 3-B – Accuracy:\",\n",
    "          accuracy_score(y_true_clean, y_pred_clean))\n",
    "    print(\"Model 3-B – ROC-AUC:\",\n",
    "          roc_auc_score(y_true_clean, y_prob_clean))\n",
    "    print(\"Confusion matrix:\\n\",\n",
    "          confusion_matrix(y_true_clean, y_pred_clean))\n",
    "    print(\"Classification report:\\n\",\n",
    "          classification_report(y_true_clean, y_pred_clean, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ea082",
   "metadata": {},
   "source": [
    "Model 3-B performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d14ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4357/4357 [==============================] - 34s 8ms/step\n",
      "Total test samples: 139415\n",
      "Valid samples after NaN-filtering: 139415\n",
      "Model 3-B – Accuracy: 0.5165297851737618\n",
      "Model 3-B – ROC-AUC: 0.4998105499207182\n",
      "Confusion matrix:\n",
      " [[    0 67403]\n",
      " [    0 72012]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.000     0.000     0.000     67403\n",
      "         1.0      0.517     1.000     0.681     72012\n",
      "\n",
      "    accuracy                          0.517    139415\n",
      "   macro avg      0.258     0.500     0.341    139415\n",
      "weighted avg      0.267     0.517     0.352    139415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\cheki\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation – Model 3-B\n",
    "# Evaluation – Model 3-B (robust to NaNs)\n",
    "import numpy as np\n",
    "from sklearn.metrics import ( accuracy_score, confusion_matrix, classification_report, roc_auc_score )\n",
    "\n",
    "# Raw probabilities from the model\n",
    "y_prob_3b = model3b.predict([X_test_m3, sym_test]).ravel()\n",
    "\n",
    "# Build a mask to remove any NaNs from either y_true or y_prob\n",
    "nan_mask = ~np.isnan(y_test_m3) & ~np.isnan(y_prob_3b)\n",
    "\n",
    "print(\"Total test samples:\", len(y_test_m3))\n",
    "print(\"Valid samples after NaN-filtering:\", nan_mask.sum())\n",
    "\n",
    "y_true_clean = y_test_m3[nan_mask]\n",
    "y_prob_clean = y_prob_3b[nan_mask]\n",
    "y_pred_clean = (y_prob_clean >= 0.5).astype(int)\n",
    "\n",
    "# Metrics on cleaned data\n",
    "print(\"Model 3-B – Accuracy:\", accuracy_score(y_true_clean, y_pred_clean))\n",
    "print(\"Model 3-B – ROC-AUC:\", roc_auc_score(y_true_clean, y_prob_clean))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true_clean, y_pred_clean))\n",
    "print(\"Classification report:\\n\", classification_report(y_true_clean, y_pred_clean, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847eb08",
   "metadata": {},
   "source": [
    "## Model 3 A & B - Interpretation:\n",
    "Both Model 3-A and Model 3-B fail to distinguish up vs. down days:\n",
    "they predict only the positive class (1.0) for every sample, resulting in:\n",
    "\n",
    "    Recall (class 1) = 1.00\n",
    "    Recall (class 0) = 0.00\n",
    "    Accuracy ≈ 0.516 (simply matches the class imbalance)\n",
    "    ROC-AUC ≈ 0.50 (no ranking ability)\n",
    "\n",
    "This indicates that the model has collapsed into a trivial classifier that always predicts “up”\n",
    "Which means the model memorizes the majority class rather than learning meaningful patterns.\n",
    "Symbol embeddings do not provide useful differentiating information with the available features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e3c3c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "## All Models – Evaluation Overview\n",
    "Because each model uses different targets, window sizes, and data splits, every model is evaluated on its **own** test set.\n",
    "\n",
    "### Classification models (binary `price_up_tomorrow`)\n",
    "1. **Model 1** – evaluated on: `X_test_m1`, `y_test_m1`  \n",
    "2. **Model 2-A** – evaluated on: `X_test_m1`, `y_test_m1`  \n",
    "3. **Model 2-B** – evaluated on: `X_test_m1`, `y_test_m1`  \n",
    "4. **Model 3-A** – evaluated on: `[X_test_m3, sym_test]`, `y_test_m3`  \n",
    "5. **Model 3-B** – evaluated on: `[X_test_m3, sym_test]`, `y_test_m3`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efdb82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "def eval_from_probs(y_true, y_prob, thr=0.5):\n",
    "    \"\"\"\n",
    "    y_true: binary {0,1}\n",
    "    y_prob: predicted probabilities [0,1]\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "\n",
    "    # Remove any NaNs in predictions\n",
    "    mask = ~np.isnan(y_prob)\n",
    "    y_true = y_true[mask]\n",
    "    y_prob = y_prob[mask]\n",
    "\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\":        f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "    # ROC-AUC only if both classes exist\n",
    "    unique = np.unique(y_true)\n",
    "    if set(unique.tolist()) == {0, 1}:\n",
    "        metrics[\"ROC-AUC\"] = roc_auc_score(y_true, y_prob)\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    else:\n",
    "        metrics[\"ROC-AUC\"] = np.nan\n",
    "        fpr, tpr = None, None\n",
    "\n",
    "    return metrics, fpr, tpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fec940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4984/4984 [==============================] - 14s 3ms/step\n",
      "4984/4984 [==============================] - 16s 3ms/step\n",
      "4984/4984 [==============================] - 16s 3ms/step\n",
      "4357/4357 [==============================] - 34s 8ms/step\n",
      "4357/4357 [==============================] - 35s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Recompute predicted probabilities for each model\n",
    "# (safe to run even if you already did it earlier)\n",
    "\n",
    "# Model 1\n",
    "y_prob_m1 = model1.predict(X_test_m1).ravel()\n",
    "\n",
    "# Model 2-A\n",
    "y_prob_2a = model2.predict(X_test_m1).ravel()\n",
    "\n",
    "# Model 2-B\n",
    "y_prob_2b = model2b.predict(X_test_m1).ravel()\n",
    "\n",
    "# Model 3-A  (multi-stock: needs symbols too)\n",
    "y_prob_3 = model3.predict([X_test_m3, sym_test]).ravel()\n",
    "\n",
    "# Model 3-B\n",
    "y_prob_3b = model3b.predict([X_test_m3, sym_test]).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "862bc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 1 ---\n",
    "m1_metrics, m1_fpr, m1_tpr = eval_from_probs(y_test_m1, y_prob_m1)\n",
    "\n",
    "# --- Model 2-A ---\n",
    "m2a_metrics, m2a_fpr, m2a_tpr = eval_from_probs(y_test_m1, y_prob_2a)\n",
    "\n",
    "# --- Model 2-B ---\n",
    "m2b_metrics, m2b_fpr, m2b_tpr = eval_from_probs(y_test_m1, y_prob_2b)\n",
    "\n",
    "# --- Model 3-A ---\n",
    "m3a_metrics, m3a_fpr, m3a_tpr = eval_from_probs(y_test_m3, y_prob_3)\n",
    "\n",
    "# --- Model 3-B ---\n",
    "m3b_metrics, m3b_fpr, m3b_tpr = eval_from_probs(y_test_m3, y_prob_3b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731624c9",
   "metadata": {},
   "source": [
    "Comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93d7cba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Accuracy  Precision  Recall        F1   ROC-AUC\n",
      "Model 1    0.520573   0.520567     1.0  0.684701  0.499919\n",
      "Model 2    0.520561   0.520561     1.0  0.684696  0.500013\n",
      "Model 3-A  0.516530   0.516530     1.0  0.681200  0.499985\n",
      "Model 3-B  0.516530   0.516530     1.0  0.681200  0.499811\n"
     ]
    }
   ],
   "source": [
    "# Comparison table\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model 1\": m1_metrics,\n",
    "    \"Model 2\": m2a_metrics,\n",
    "    \"Model 3-A\": m3a_metrics,\n",
    "    \"Model 3-B\": m3b_metrics,\n",
    "}).T\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cef5d5",
   "metadata": {},
   "source": [
    "ROC curve for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f2f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Model 1\n",
    "if m1_fpr is not None:\n",
    "    plt.plot(m1_fpr, m1_tpr, label='Model 1')\n",
    "# Model 2  (use m2a_*)\n",
    "if m2a_fpr is not None:\n",
    "    plt.plot(m2a_fpr, m2a_tpr, label='Model 2')\n",
    "# Model 3-A\n",
    "if m3a_fpr is not None:\n",
    "    plt.plot(m3a_fpr, m3a_tpr, label='Model 3-A')\n",
    "# Model 3-B\n",
    "if m3b_fpr is not None:\n",
    "    plt.plot(m3b_fpr, m3b_tpr, label='Model 3-B')\n",
    "# Random baseline\n",
    "plt.plot([0,1], [0,1], 'k--', label='Random')\n",
    "\n",
    "plt.title(\"ROC Curves for All Models\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343ff53",
   "metadata": {},
   "source": [
    "ROC curve plot shows that every model’s ROC curve lying exactly on the random classifier, emphasizing that the models can’t rank “up” days above “down” or show no discriminative power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f003c",
   "metadata": {},
   "source": [
    "## All Models performance observations:\n",
    "\n",
    "Models 1, 2 are now numerically stable after cleaning and training and all converge to the same trivial solution, predicting the majority class (“up”) for every sample. Despite different architectures, their accuracy (~0.520) and ROC-AUC ≈ 0.50 show no discriminative ability.\n",
    "\n",
    "Models 3-A and 3-B are numerically stable but collapse to a trivial strategy that predicts the majority class (“up”) for every sample. Their accuracy (~0.516) reflects class imbalance, and ROC-AUC ≈ 0.50 confirms no ranking ability. The deeper embedding and denser layers in 3-B offer no improvement.\n",
    "\n",
    "**Takeaway:**\n",
    "\n",
    "Increasing model depth, adding dense heads, or introducing symbol embeddings does not overcome the lack of predictive signal in short-horizon price data. Meaningful improvement will require richer feature sets (technical indicators, order-book information, sentiment, macroeconomic factors) and longer historical context, rather than additional architectural complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
